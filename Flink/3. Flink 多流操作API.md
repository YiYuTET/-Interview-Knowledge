# 3. Flink 多流操作API


## 3.1 split分流操作[已deprecated]


<table><tr><td bgcolor=Gainsboro><font size=4><b>split拆分 (DataStream -> SplitStream)</td></tr></table>

<font size=3><b>该方法是将一个DataStream中的数据流打上不同的标签，逻辑的拆分成多个不同类型的流，返回一个新的SplitStream，本质上还是一个数据流，只不过是将流中的数据打上了不同的标签。

返回的SplitStream已经标记为过时，1.12版本已经删除了split和select方法，可以使用测流输出代替。
</b></font>



## 3.2 分流操作[使用测流输出]

```java
public class _13_SideOutput_Demo {
    public static void main(String[] args) throws Exception {
        Configuration configuration = new Configuration();
        configuration.setInteger("rest.port", 8822);
        StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironmentWithWebUI(configuration);

        //开启checkpoint
        env.enableCheckpointing(5000, CheckpointingMode.EXACTLY_ONCE);
        env.getCheckpointConfig().setCheckpointStorage("file:///d:/ckpt");

        DataStreamSource<EventLog> streamSource = env.addSource(new MySourceFunction());


        /**
         * 需求：将事件进行分流
         * appLaunch事件分到一个流
         * putBack事件分到一个流
         * 其它事件保留在主流
         */
        SingleOutputStreamOperator<EventLog> processed = streamSource.process(new ProcessFunction<EventLog, EventLog>() {

            /**
             *
             * @param eventLog 输入数据
             * @param context 上下文，它能提供“侧输出”功能
             * @param collector 主流输出收集器
             * @throws Exception
             */
            @Override
            public void processElement(EventLog eventLog, ProcessFunction<EventLog, EventLog>.Context context, Collector<EventLog> collector) throws Exception {
                if (eventLog.getEventId().equals("appLaunch")) {
                    context.output(new OutputTag<EventLog>("launch", TypeInformation.of(EventLog.class)), eventLog);
                } else if ("putBack".equals(eventLog)) {
                    context.output(new OutputTag<String>("back", TypeInformation.of(String.class)), JSON.toJSONString(eventLog));
                }
                collector.collect(eventLog);
            }
        });

        //获取 launch测流数据
        DataStream<EventLog> launchStream = processed.getSideOutput(new OutputTag<EventLog>("launch", TypeInformation.of(EventLog.class)));

        //获取 back测流数据
        DataStream<String> backStream = processed.getSideOutput(new OutputTag<String>("back", TypeInformation.of(String.class)));

        launchStream.print();
        backStream.print();
        
        env.execute();
    }
}
```



## 3.3 sideOutput测流输出

<font size=3><b>以下function函数，支持将特定数据输出到测流中。
- ProcessFunction
- KeyedProcessFunction
- CoProcessFunction
- KeyedCoProcessFunction
- ProcessWindowFunction
- ProcessAllWindowFunction
</b></font>

```java
        DataStream<Integer> input = ...;

        final OutputTag<String> outputTag = new OutputTag<String>("side-output"){};
        SingleOutputStreamOperator<Integer> mainDataStream = input.process(new ProcessFunction<Integer, Integer>() {
            @Override
            public void processElement(Integer integer, ProcessFunction<Integer, Integer>.Context context, Collector<Integer> collector) throws Exception {
                //输出到主流
                collector.collect(integer);
                //输出到测流
                context.output(outputTag, "sideout-" + String.valueOf(integer));
            }
        });
        //通过"主流"获取侧流
        DataStream<String> sideOutputStream = mainDataStream.getSideOutput(outputTag);
```



## 3.4 connect连接操作

<table><tr><td bgcolor=Gainsboro><font size=4><b>connect连接 (DataStream,DataStream -> ConnectedStreams)</td></tr></table>

<font size=3><b>connect翻译成中文意思为连接，可以将两个数据类型一样也可以不一样的DataStream连接成一个新的ConnectedStreams。需要注意的是，connect方法与union方法不同，虽然调用connect方法将两个流连接成一个新的ConnectedStreams，但是里面的两个流依然是相互独立的，++这个方法最大的好处是可以让两个流共享State状态++，状态相关的内容在后面章节介绍。
</b></font>

```java
//创建两个DataStream
DataStreamSource<String> word = env.fromElements("a", "b", "c", "d");
DataStreamSource<Integer> num = env.fromElements(1, 2, 3);
//将两个DataStream连接到一起
ConnectedStreams<String, Integer> connected = word.connect(num);
```


<table><tr><td bgcolor=Gainsboro><font size=4><b>coMap (ConnectedStreams -> DataStream)</td></tr></table>

<font size=3><b>对ConnectedStreams调用map方法时需要传入CoMapFunction函数；
该接口需要指定3个泛型：
1. 第一个输入DataStream的数据类型
2. 第二个输入DataStream的数据类型
3. 返回结果的数据类型

该接口需要重写两个方法：
1. map1方法，是对第1个流进行map的处理逻辑
2. map2方法，是对第2个流进行map的处理逻辑

这两个方法必须是相同的返回类型。
</b></font>

```java
        //将两个DataStream连接到一起
        ConnectedStreams<String, Integer> wordAndNum = word.connect(num);
        //对ConnectedStream中两个流分别调用两不同逻辑的map方法
        SingleOutputStreamOperator<String> result = wordAndNum.map(new CoMapFunction<String, Integer, String>() {
            @Override
            public String map1(String s) throws Exception {
                return s.toUpperCase();
            }

            @Override
            public String map2(Integer integer) throws Exception {
                return String.valueOf(integer * 10);
            }
        });
```



<table><tr><td bgcolor=Gainsboro><font size=4><b>coFlatMap (ConnectedStreams -> DataStream)</td></tr></table>

<font size=3><b>对ConnectedStreams调用flatMap方法。调用flatMap方法，传入的Function是CoFlatMapFunction；

该接口需要重写两个方法：
1. flatMap1方法，是对第1个流进行flatMap的处理逻辑
2. flatMap2方法，是对第2个流进行flatMap的处理逻辑

这两个方法必须是相同的返回类型。
</b></font>


```java
        //创建两个DataStream
        DataStreamSource<String> word = env.fromElements("a b c", "d e f");
        DataStreamSource<String> num = env.fromElements("1,2,3", "4,5,6");
        //将两个DataStream连接到一起
        ConnectedStreams<String, String> connected = word.connect(num);
        //对ConnectedStream中两个流分别调用两不同逻辑的flatMap方法
        SingleOutputStreamOperator<String> result = connected.flatMap(new CoFlatMapFunction<String, String, String>() {
            @Override
            public void flatMap1(String s, Collector<String> collector) throws Exception {
                String[] words = s.split(" ");
                for (String w : words) {
                    collector.collect(w);
                }
            }

            @Override
            public void flatMap2(String s, Collector<String> collector) throws Exception {
                String[] nums = s.split(",");
                for (String n : nums) {
                    collector.collect(n);
                }
            }
        });
```



## 3.5 union合并操作

<table><tr><td bgcolor=Gainsboro><font size=4><b>union合并 (DataStream * -> DataStream)</td></tr></table>

<font size=3><b>该方法可以将两个或者多个数据类型一致的DataStream合并成一个DataStream。DataStream<T> union(DataStream<T> ... streams)可以看出DataStream的union方法的参数为可变参数，即可以合并两个或多个数据类型一致的DataStream。
下面的例子是使用fromElements生成两个DataStream，一个是奇数的，一个是偶数的，然后将两个DataStream合并成一个DataStream。
</b></font>

```java
DataStreamSource<Integer> odd = env.fromElements(1, 3, 5, 7, 9);
DataStreamSource<Integer> even = env.fromElements(2, 4, 6, 8, 10);
DataStream<Integer> result = odd.union(even);
```

## 3.6 coGroup协同分组


<font size=3><b>coGroup本质上是join算子的底层算子，功能类似。
</b></font>


```java
DataStreamSource<String> stream1 = env.fromElements("1,aa,m,18", "2,bb,m,28", "3,cc,f,38");
DataStreamSource<String> stream2 = env.fromElements("1:aa:m:18", "2:bb:m:28", "3:cc:f:38");

                         //左边数据流的哪个字段与右边数据流的哪个字段
DataStream<String> coGroup = stream1.coGroup(stream2).where(new KeySelector<String, String>() {
            @Override
            public String getKey(String s) throws Exception {
                return s;
            }
        }).equalTo(new KeySelector<String, String>() {
            @Override
            public String getKey(String s) throws Exception {
                return s;
            }
        }).window(TumblingEventTimeWindows.of(Time.seconds(5)))
        .apply(new CoGroupFunction<String, String, String>() {
            /**
             *
             * @param iterable 左边迭代器，5s内左边数据流的一组
             * @param iterable1 右边迭代器，5s内右边数据流的一组
             * @param collector
             * @throws Exception
             */
            @Override
            public void coGroup(Iterable<String> iterable, Iterable<String> iterable1, Collector<String> collector) throws Exception {

            }
        });
```


## 3.7 join关联操作

<font size=3><b>用于关联两个流(类似于sql中的join)，还需要指定join的条件，需要在窗口中进行关联后的逻辑计算。
</b></font>

<table><tr><td bgcolor=Gainsboro><font size=4><b>join算子的代码结构：</td></tr></table>

```java
stream.join(otherStream)
      .where(KeySelector)
      .equalTo(KeySelector)
      .window(WindowAssigner)
      .apply(JoinFunction)
```



## 3.8 broadcast广播

<font size=3><b>Broadcast State是Flink 1.5引入的新特性。
在开发过程中，如果遇到需要下发广播配置、规则等低吞吐事件流到下游所有task时，就可以使用Broadcast State特性。下游的task接收这些配置、规则并保存为Broadcast State，将这些配置应用到另一个数据流的计算中。
</b></font>

<table><tr><td bgcolor=Gainsboro><font size=4><b>API介绍</td></tr></table>

<font size=3><b>通常，我们首先会创建一个Keyed或Non-Keyed的DataStream，然后再创建一个BroadcastedStream，最后通过DataStream来连接(调用connect方法)到BroadcastedStream上，这样实现将Broadcast State广播到DataStream下游的每个Task中。如果DataStream是KeyedStream，则连接到BroadcastedStream后，添加处理ProcessFunction时需要使用KeyedBroadcastProcessFunction来实现，下面是KeyedBroadcastProcessFunction的API，代码如下所示：
</b></font>

<font color=Red size=3><b>详见
https://www.bilibili.com/video/BV1K44y1g7wA?p=41&vd_source=26668f0ed33317a00612f0d4c98799c9
P41
</b></font>